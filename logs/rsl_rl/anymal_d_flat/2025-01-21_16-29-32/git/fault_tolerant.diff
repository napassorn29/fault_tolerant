--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/anymal_d_flat/2025-01-17_15-41-29/events.out.tfevents.1737103301.fibo3.60261.0
	logs/rsl_rl/anymal_d_flat/2025-01-21_15-32-46/
	logs/rsl_rl/anymal_d_flat/2025-01-21_16-29-32/
	outputs/2025-01-21/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc
index 8b423d7..4e6f97f 100644
Binary files a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc and b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc differ
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc
index 122ee9e..4ce6bf3 100644
Binary files a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc and b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc differ
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
index b50dad1..20c22d9 100644
--- a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
+++ b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
@@ -135,7 +135,8 @@ def step_reward(
     command_name: str,
     asset_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
     sensor_cfg: SceneEntityCfg | None = None,
-    weight_lin_vel: float = 1.1,
+    weight_lin_vel: float = 1.15,
+    weight_exp_height: float = 1.0,
     weight_height_toggle: float = 1.0,
 ) -> torch.Tensor:
     """Combined reward function based on height condition.
@@ -166,22 +167,28 @@ def step_reward(
     # Get the current height of the asset
     current_height = asset.data.root_link_pos_w[:, 2]
 
-    # Calculate rewards
-    height_toggle_reward = weight_height_toggle * (current_height < adjusted_target_height).float()
-
-    lin_vel_reward = weight_lin_vel * torch.exp(
-        -torch.sum(
-            torch.square(
-                env.command_manager.get_command(command_name)[:, :2]
-                - asset.data.root_com_lin_vel_b[:, :2]
-            ),
-            dim=1,
-        ) / std**2
+    # Calculate velocity reward
+    lin_vel_error = torch.sum(
+        torch.square(
+            env.command_manager.get_command(command_name)[:, :2]
+            - asset.data.root_com_lin_vel_b[:, :2]
+        ),
+        dim=1,
     )
+    lin_vel_reward = torch.exp(-lin_vel_error / std**2) * weight_lin_vel
+
+    # Calculate exponential height reward
+    height_difference = adjusted_target_height - current_height
+    exp_height_reward = (1 - torch.exp(-torch.square(height_difference))) * weight_exp_height
+
+    # Calculate height toggle reward
+    height_toggle_reward = weight_height_toggle * (current_height < adjusted_target_height).float()
 
     # Combine rewards based on the height condition
     combined_reward = torch.where(
-        current_height >= adjusted_target_height, lin_vel_reward, height_toggle_reward
+        current_height >= adjusted_target_height,
+        lin_vel_reward * exp_height_reward,  # Multiply rewards when condition is met
+        height_toggle_reward
     )
 
-    return combined_reward
+    return combined_reward
\ No newline at end of file
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
index 4e1e38d..5f79d57 100644
--- a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
+++ b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
@@ -271,8 +271,9 @@ class RewardsCfg:
             "target_height": 0.44,  # Example target height
             "std": math.sqrt(0.25),  # Standard deviation for lin vel reward
             "command_name": "base_velocity",  # Command name for velocity tracking
-            "weight_lin_vel": 1.1,  # Weight for the lin vel reward
-            "weight_height_toggle": 1.0,  # Weight for the height toggle reward
+            "weight_lin_vel" : 1.15,
+            "weight_exp_height" : 1.0,
+            "weight_height_toggle" : 1.0,
             # Optional: "sensor_cfg": SceneEntityCfg("sensor_name")
         },
     )