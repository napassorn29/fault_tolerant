--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
	modified:   exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/anymal_d_flat/2025-01-17_15-41-29/events.out.tfevents.1737103301.fibo3.60261.0
	logs/rsl_rl/anymal_d_flat/2025-01-20_14-58-01/
	outputs/2025-01-20/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc
index 7117526..8b423d7 100644
Binary files a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc and b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/__pycache__/velocity_env_cfg.cpython-310.pyc differ
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc
index bca1a73..122ee9e 100644
Binary files a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc and b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/__pycache__/rewards.cpython-310.pyc differ
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
index a148bef..b50dad1 100644
--- a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
+++ b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/mdp/rewards.py
@@ -122,3 +122,66 @@ def base_height_toggle(
     reward_toggle = (current_height >= target_height).float()
 
     return reward_toggle
+
+
+"""
+Step reward for get up and walk
+"""
+
+def step_reward(
+    env: ManagerBasedRLEnv,
+    target_height: float,
+    std: float,
+    command_name: str,
+    asset_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
+    sensor_cfg: SceneEntityCfg | None = None,
+    weight_lin_vel: float = 1.1,
+    weight_height_toggle: float = 1.0,
+) -> torch.Tensor:
+    """Combined reward function based on height condition.
+
+    Args:
+        env: Manager-based RL environment.
+        target_height: Target height for the asset.
+        std: Standard deviation for the XY velocity task reward.
+        command_name: Name of the command to track.
+        asset_cfg: Configuration for the asset entity (default: robot).
+        sensor_cfg: Optional sensor configuration for height adjustment.
+        weight_lin_vel: Weight for the XY velocity reward.
+        weight_height_toggle: Weight for the height toggle reward.
+
+    Returns:
+        torch.Tensor: Combined reward value.
+    """
+    # Extract the asset for height calculations
+    asset: RigidObject = env.scene[asset_cfg.name]
+
+    # Adjust the target height if a sensor is provided
+    if sensor_cfg is not None:
+        sensor: RayCaster = env.scene[sensor_cfg.name]
+        adjusted_target_height = target_height + sensor.data.pos_w[:, 2]
+    else:
+        adjusted_target_height = target_height
+
+    # Get the current height of the asset
+    current_height = asset.data.root_link_pos_w[:, 2]
+
+    # Calculate rewards
+    height_toggle_reward = weight_height_toggle * (current_height < adjusted_target_height).float()
+
+    lin_vel_reward = weight_lin_vel * torch.exp(
+        -torch.sum(
+            torch.square(
+                env.command_manager.get_command(command_name)[:, :2]
+                - asset.data.root_com_lin_vel_b[:, :2]
+            ),
+            dim=1,
+        ) / std**2
+    )
+
+    # Combine rewards based on the height condition
+    combined_reward = torch.where(
+        current_height >= adjusted_target_height, lin_vel_reward, height_toggle_reward
+    )
+
+    return combined_reward
diff --git a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
index 1d085f2..4e1e38d 100644
--- a/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
+++ b/exts/extensions/extensions/tasks/locomotion_recovery/velocity/velocity_env_cfg.py
@@ -220,9 +220,9 @@ class RewardsCfg:
     """Reward terms for the MDP."""
 
     # -- task
-    track_lin_vel_xy_exp = RewTerm(
-        func=mdp.track_lin_vel_xy_exp, weight=1.1, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
-    )
+    # track_lin_vel_xy_exp = RewTerm(
+    #     func=mdp.track_lin_vel_xy_exp, weight=1.1, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
+    # )
     track_ang_vel_z_exp = RewTerm(
         func=mdp.track_ang_vel_z_exp, weight=0.5, params={"command_name": "base_velocity", "std": math.sqrt(0.25)}
     )
@@ -264,6 +264,19 @@ class RewardsCfg:
             # "asset_cfg": SceneEntityCfg("robot"),
         },
     )
+    step_reward = RewTerm(
+        func=mdp.step_reward,
+        weight=1.0,  # Adjust weight if needed
+        params={
+            "target_height": 0.44,  # Example target height
+            "std": math.sqrt(0.25),  # Standard deviation for lin vel reward
+            "command_name": "base_velocity",  # Command name for velocity tracking
+            "weight_lin_vel": 1.1,  # Weight for the lin vel reward
+            "weight_height_toggle": 1.0,  # Weight for the height toggle reward
+            # Optional: "sensor_cfg": SceneEntityCfg("sensor_name")
+        },
+    )
+
     # -- optional penalties
     flat_orientation_l2 = RewTerm(func=mdp.flat_orientation_l2, weight=0.0)
     dof_pos_limits = RewTerm(func=mdp.joint_pos_limits, weight=0.0)